"""–û–±—É—á–µ–Ω–∏–µ YOLO –º–æ–¥–µ–ª–∏ —Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π MLflow"""

import os
from pathlib import Path
from typing import Dict, Any, Optional
import mlflow
from ultralytics import YOLO
from loguru import logger


def train_yolo_with_mlflow(
    config: Dict[str, Any], data_yaml: str, output_dir: str, base_path: Path = None
) -> dict:
    """
    –û–±—É—á–µ–Ω–∏–µ YOLO –º–æ–¥–µ–ª–∏ —Å –ø–æ–ª–Ω—ã–º —Ç—Ä–µ–∫–∏–Ω–≥–æ–º –≤ MLflow

    Args:
        config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è –∏–∑ config.yaml
        data_yaml: –ü—É—Ç—å –∫ YAML —Ñ–∞–π–ª—É —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π –¥–∞—Ç–∞—Å–µ—Ç–∞
        output_dir: –ü–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        base_path: –ë–∞–∑–æ–≤—ã–π –ø—É—Ç—å –ø—Ä–æ–µ–∫—Ç–∞ (–¥–ª—è –ø–æ–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π)

    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –æ–±—É—á–µ–Ω–∏—è
    """
    if base_path is None:
        base_path = Path(output_dir).parent

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ MLflow
    mlflow_config = config.get("mlflow", {})
    tracking_uri = mlflow_config.get("tracking_uri", "runs/mlflow")
    experiment_name = mlflow_config.get("experiment_name", "yolo_training")
    log_artifacts = mlflow_config.get("log_artifacts", True)
    log_images = mlflow_config.get("log_images", True)
    log_model = mlflow_config.get("log_model", True)

    # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è MLflow
    tracking_path = Path(tracking_uri)
    tracking_path.mkdir(parents=True, exist_ok=True)

    # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º MLflow
    # MLflow —Ç—Ä–µ–±—É–µ—Ç file:// –ø—Ä–µ—Ñ–∏–∫—Å –¥–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö –ø—É—Ç–µ–π
    # –ù–∞ Windows –Ω—É–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—É—Ç–∏ —Å –ø—Ä–æ–±–µ–ª–∞–º–∏ –∏ –∫–∏—Ä–∏–ª–ª–∏—Ü–µ–π
    import platform
    from urllib.request import pathname2url

    abs_path = tracking_path.absolute()
    if platform.system() == "Windows":
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º pathname2url –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è –ø—É—Ç–∏
        # –≠—Ç–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∞–µ—Ç –ø—Ä–æ–±–µ–ª—ã –∏ –∫–∏—Ä–∏–ª–ª–∏—Ü—É
        encoded_path = pathname2url(str(abs_path))
        # –î–ª—è Windows –Ω—É–∂–µ–Ω —Ñ–æ—Ä–º–∞—Ç file:///C:/path (3 —Å–ª–µ—à–∞)
        mlflow_uri = f"file:{encoded_path}"
    else:
        mlflow_uri = f"file://{abs_path}"

    mlflow.set_tracking_uri(mlflow_uri)
    logger.debug(f"MLflow tracking URI —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: {mlflow_uri}")

    # –°–æ–∑–¥–∞–µ–º –∏–ª–∏ –ø–æ–ª—É—á–∞–µ–º —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç
    try:
        experiment = mlflow.get_experiment_by_name(experiment_name)
        if experiment is None:
            experiment_id = mlflow.create_experiment(experiment_name)
            logger.info(f"–°–æ–∑–¥–∞–Ω –Ω–æ–≤—ã–π —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç MLflow: {experiment_name}")
        else:
            experiment_id = experiment.experiment_id
            logger.info(
                f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç MLflow: {experiment_name}"
            )
    except Exception as e:
        logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–º MLflow: {e}. –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π.")
        experiment_id = mlflow.create_experiment(experiment_name)

    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è
    model_name = config.get("model", "yolo11n.pt")
    epochs = config.get("epochs", 100)
    imgsz = config.get("imgsz", 640)
    batch = config.get("batch", 16)
    device = config.get("device", "cuda")
    workers = config.get("workers", 8)
    cache = config.get("cache", True)
    lr0 = config.get("lr0", 0.01)
    lrf = config.get("lrf", 0.01)
    save_period = config.get("save_period", 10)
    patience = config.get("patience", 50)

    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–æ–æ–±—É—á–µ–Ω–∏—è
    resume_config = config.get("resume_training", {})
    resume_enabled = resume_config.get("enabled", False)
    resume_model_path = resume_config.get("model_path", None)
    resume_from_checkpoint = resume_config.get("resume_from_checkpoint", False)
    fine_tune_lr0 = resume_config.get("fine_tune_lr0", None)

    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
    augment_config = config.get("augment", {})

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–æ–µ–∫—Ç–∞
    project_dir = Path(output_dir) / "training"
    project_dir.mkdir(parents=True, exist_ok=True)

    # –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ models –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    paths_config = config.get("paths", {}) if "paths" in config else {}
    models_dir_path = None
    if base_path and paths_config.get("models_dir"):
        models_dir_path = base_path / paths_config["models_dir"]
        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É models, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
        models_dir_path.mkdir(parents=True, exist_ok=True)

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–æ–¥–µ–ª—å –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ (–¥–æ–æ–±—É—á–µ–Ω–∏–µ –∏–ª–∏ —Å –Ω—É–ª—è)
    actual_model_path = model_name
    is_resume_training = False
    start_epoch = 0

    if resume_enabled:
        if resume_model_path:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è
            if resume_model_path in ["best.pt", "last.pt"]:
                # –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –ø—É—Ç–∏ - –∏—â–µ–º –≤ –ø—Ä–µ–¥—ã–¥—É—â–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –æ–±—É—á–µ–Ω–∏—è
                prev_training_dir = (
                    Path(output_dir) / "training" / "yolo_training" / "weights"
                )
                resume_model_full_path = prev_training_dir / resume_model_path

                if not resume_model_full_path.exists():
                    # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –≤ –¥—Ä—É–≥–∏—Ö –≤–æ–∑–º–æ–∂–Ω—ã—Ö –º–µ—Å—Ç–∞—Ö
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –±–∞–∑–æ–≤—É—é –ø–∞–ø–∫—É rest
                    rest_dir = (
                        Path(output_dir).parent
                        if "rest" in str(output_dir)
                        else Path(output_dir)
                    )
                    base_project_dir = (
                        rest_dir.parent if rest_dir.name == "rest" else rest_dir
                    )

                    possible_paths = []

                    # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞–ø–∫—É models (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω–∞—è)
                    if models_dir_path:
                        possible_paths.append(models_dir_path / resume_model_path)

                    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –º–µ—Å—Ç–∞ –æ–±—É—á–µ–Ω–∏—è
                    possible_paths.extend(
                        [
                            Path(output_dir)
                            / "training"
                            / "yolo_training"
                            / "weights"
                            / resume_model_path,
                            rest_dir
                            / "outputs"
                            / "training"
                            / "yolo_training"
                            / "weights"
                            / resume_model_path,
                            rest_dir / "models" / resume_model_path,
                            rest_dir / resume_model_path,
                            base_project_dir / resume_model_path,
                            base_project_dir / "rest" / resume_model_path,
                            Path(output_dir).parent
                            / "training"
                            / "yolo_training"
                            / "weights"
                            / resume_model_path,
                        ]
                    )

                    # –¢–∞–∫–∂–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º runs/detect –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å–æ —Å—Ç–∞—Ä—ã–º–∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–º–∏
                    if base_project_dir:
                        runs_detect_dir = base_project_dir / "runs" / "detect"
                        if runs_detect_dir.exists():
                            for train_dir in runs_detect_dir.iterdir():
                                if train_dir.is_dir():
                                    weights_file = (
                                        train_dir / "weights" / resume_model_path
                                    )
                                    if weights_file.exists():
                                        possible_paths.append(weights_file)

                    logger.debug(
                        f"–ü–æ–∏—Å–∫ –º–æ–¥–µ–ª–∏ {resume_model_path} –≤ —Å–ª–µ–¥—É—é—â–∏—Ö –º–µ—Å—Ç–∞—Ö:"
                    )
                    for path in possible_paths:
                        logger.debug(f"  - {path}")
                        if path.exists():
                            resume_model_full_path = path
                            logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å –Ω–∞–π–¥–µ–Ω–∞: {resume_model_full_path}")
                            break
                    else:
                        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã—Ö –ø—É—Ç–µ–π –¥–ª—è —Å–æ–æ–±—â–µ–Ω–∏—è –æ–± –æ—à–∏–±–∫–µ
                        checked_paths_str = "\n".join(
                            [f"  - {p}" for p in possible_paths[:5]]
                        )
                        raise FileNotFoundError(
                            f"–ú–æ–¥–µ–ª—å –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è '{resume_model_path}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.\n"
                            f"–ü—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–µ –º–µ—Å—Ç–∞:\n{checked_paths_str}\n"
                            f"–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: –ø–µ—Ä–µ–º–µ—Å—Ç–∏—Ç–µ –º–æ–¥–µ–ª—å –≤ –ø–∞–ø–∫—É 'rest/models/' –∏–ª–∏ —É–∫–∞–∂–∏—Ç–µ –ø–æ–ª–Ω—ã–π –ø—É—Ç—å –≤ model_path"
                        )
            else:
                # –ê–±—Å–æ–ª—é—Ç–Ω—ã–π –∏–ª–∏ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å
                resume_model_full_path = Path(resume_model_path)
                if not resume_model_full_path.is_absolute():
                    resume_model_full_path = Path(output_dir).parent / resume_model_path

                if not resume_model_full_path.exists():
                    raise FileNotFoundError(
                        f"–ú–æ–¥–µ–ª—å –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {resume_model_full_path}"
                    )

            actual_model_path = str(resume_model_full_path.absolute())
            is_resume_training = True

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –º–æ–∂–Ω–æ –ª–∏ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ (resume=True)
            if resume_from_checkpoint and resume_model_path == "last.pt":
                logger.info(
                    "üîÑ –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —á–µ–∫–ø–æ–∏–Ω—Ç–∞ (resume=True)"
                )
            else:
                logger.info(f"üîÑ –î–æ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏: {actual_model_path}")
                logger.info("   (–û–±—É—á–µ–Ω–∏–µ –Ω–∞—á–Ω–µ—Ç—Å—è —Å —ç–ø–æ—Ö–∏ 0, –∏—Å–ø–æ–ª—å–∑—É—è –≤–µ—Å–∞ –º–æ–¥–µ–ª–∏)")
        else:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å, –Ω–æ –ª–æ–≥–∏—Ä—É–µ–º —á—Ç–æ —ç—Ç–æ –¥–æ–æ–±—É—á–µ–Ω–∏–µ
            logger.warning(
                "resume_training.enabled=True, –Ω–æ model_path –Ω–µ —É–∫–∞–∑–∞–Ω. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –±–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å."
            )
            is_resume_training = True

    logger.info("=" * 80)
    if is_resume_training:
        logger.info("–ù–ê–ß–ê–õ–û –î–û–û–ë–£–ß–ï–ù–ò–Ø YOLO –ú–û–î–ï–õ–ò")
    else:
        logger.info("–ù–ê–ß–ê–õ–û –û–ë–£–ß–ï–ù–ò–Ø YOLO –ú–û–î–ï–õ–ò")
    logger.info("=" * 80)
    logger.info(f"–ú–æ–¥–µ–ª—å: {actual_model_path}")
    logger.info(f"–î–∞—Ç–∞—Å–µ—Ç: {data_yaml}")
    logger.info(f"–≠–ø–æ—Ö: {epochs}")
    logger.info(f"–†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {imgsz}")
    logger.info(f"Batch size: {batch}")
    logger.info(f"–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
    logger.info(f"MLflow —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç: {experiment_name}")

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º fine-tune learning rate, –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω
    actual_lr0 = (
        fine_tune_lr0 if (fine_tune_lr0 is not None and is_resume_training) else lr0
    )
    if is_resume_training and fine_tune_lr0 is not None:
        logger.info(f"Learning rate –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è: {actual_lr0} (–≤–º–µ—Å—Ç–æ {lr0})")

    # –ù–∞—á–∏–Ω–∞–µ–º MLflow run
    with mlflow.start_run(experiment_id=experiment_id) as run:
        run_id = run.info.run_id
        logger.info(f"MLflow Run ID: {run_id}")

        # –õ–æ–≥–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        mlflow.log_params(
            {
                "model": actual_model_path if is_resume_training else model_name,
                "is_resume_training": is_resume_training,
                "epochs": epochs,
                "imgsz": imgsz,
                "batch": batch,
                "device": device,
                "workers": workers,
                "lr0": actual_lr0,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–∫—Ç—É–∞–ª—å–Ω—ã–π LR
                "lrf": lrf,
                "patience": patience,
            }
        )

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è
        if is_resume_training:
            mlflow.log_params(
                {
                    "resume_model_path": str(actual_model_path),
                    "resume_from_checkpoint": (
                        resume_from_checkpoint if resume_enabled else False
                    ),
                    "fine_tune_lr0": (
                        fine_tune_lr0 if fine_tune_lr0 is not None else "default"
                    ),
                }
            )

        # –õ–æ–≥–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
        if augment_config:
            mlflow.log_params({f"augment_{k}": v for k, v in augment_config.items()})

        # –õ–æ–≥–∏—Ä—É–µ–º –ø—É—Ç—å –∫ –¥–∞—Ç–∞—Å–µ—Ç—É
        mlflow.log_param("data_yaml", str(Path(data_yaml).absolute()))

        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
            logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ {actual_model_path}...")
            model = YOLO(actual_model_path)

            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
            train_args = {
                "data": data_yaml,
                "epochs": epochs,
                "imgsz": imgsz,
                "batch": batch,
                "device": device,
                "workers": workers,
                "lr0": actual_lr0,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–∫—Ç—É–∞–ª—å–Ω—ã–π LR (–º–æ–∂–µ—Ç –±—ã—Ç—å –∏–∑–º–µ–Ω–µ–Ω –¥–ª—è fine-tuning)
                "lrf": lrf,
                "patience": patience,
                "project": str(project_dir),
                "name": "yolo_training",
                "save_period": save_period,
                "exist_ok": True,
                "verbose": True,
            }

            # –î–æ–±–∞–≤–ª—è–µ–º resume –ø–∞—Ä–∞–º–µ—Ç—Ä, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ
            # –í YOLO resume –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å True –∏–ª–∏ –ø—É—Ç—å –∫ last.pt —á–µ–∫–ø–æ–∏–Ω—Ç—É
            if is_resume_training and resume_from_checkpoint:
                # –ï—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º last.pt, –ø–µ—Ä–µ–¥–∞–µ–º –ø—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ –¥–ª—è resume
                if resume_model_path == "last.pt":
                    train_args["resume"] = actual_model_path
                    logger.info(
                        f"–ü–∞—Ä–∞–º–µ—Ç—Ä resume={actual_model_path} —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω - –æ–±—É—á–µ–Ω–∏–µ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—Å—è —Å –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è"
                    )
                else:
                    # –î–ª—è –¥—Ä—É–≥–∏—Ö –ø—É—Ç–µ–π —Ç–∞–∫–∂–µ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å resume
                    train_args["resume"] = actual_model_path
                    logger.info(
                        f"–ü–∞—Ä–∞–º–µ—Ç—Ä resume={actual_model_path} —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω - –ø–æ–ø—ã—Ç–∫–∞ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ"
                    )

            # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è
            if cache:
                train_args["cache"] = "ram" if device == "cuda" else "disk"

            # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
            if augment_config:
                train_args.update(augment_config)

            # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ
            logger.info("–ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è...")
            results = model.train(**train_args)

            # –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç—å –∫ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
            best_model_path = (
                Path(project_dir) / "yolo_training" / "weights" / "best.pt"
            )

            # –¢–∞–∫–∂–µ –∫–æ–ø–∏—Ä—É–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å –≤ –ø–∞–ø–∫—É models —Å –ø–æ–Ω—è—Ç–Ω—ã–º –∏–º–µ–Ω–µ–º (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            if models_dir_path and best_model_path.exists():
                try:
                    from datetime import datetime

                    date_str = datetime.now().strftime("%Y-%m-%d")
                    model_copy_name = f"model_{date_str}_soldier_detection.pt"
                    model_copy_path = models_dir_path / model_copy_name

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —É–∂–µ —Ç–∞–∫–∞—è –º–æ–¥–µ–ª—å
                    counter = 1
                    while model_copy_path.exists():
                        model_copy_name = (
                            f"model_{date_str}_soldier_detection_v{counter}.pt"
                        )
                        model_copy_path = models_dir_path / model_copy_name
                        counter += 1

                    import shutil

                    shutil.copy2(str(best_model_path), str(model_copy_path))
                    logger.info(
                        f"üì¶ –ö–æ–ø–∏—è –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {model_copy_path}"
                    )
                except Exception as e:
                    logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å –≤ –ø–∞–ø–∫—É models: {e}")

            if not best_model_path.exists():
                # –ü—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –ø—É—Ç—å
                runs_dir = Path(project_dir) / "yolo_training"
                if runs_dir.exists():
                    weights_dir = list(runs_dir.glob("weights"))
                    if weights_dir:
                        best_model_path = weights_dir[0] / "best.pt"

            logger.info(f"–û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
            logger.info(f"–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {best_model_path}")

            # –õ–æ–≥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—É—á–µ–Ω–∏—è
            if hasattr(results, "results_dict"):
                metrics = results.results_dict
                # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
                numeric_metrics = {
                    k: v
                    for k, v in metrics.items()
                    if isinstance(v, (int, float)) and not k.startswith("_")
                }
                mlflow.log_metrics(numeric_metrics)
                logger.info("–ú–µ—Ç—Ä–∏–∫–∏ –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞–Ω—ã –≤ MLflow")

            # –õ–æ–≥–∏—Ä—É–µ–º –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã
            if log_artifacts and best_model_path.exists():
                # –õ–æ–≥–∏—Ä—É–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
                if log_model:
                    mlflow.log_artifact(str(best_model_path), artifact_path="models")
                    logger.info("–ú–æ–¥–µ–ª—å –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∞ –≤ MLflow")

                # –õ–æ–≥–∏—Ä—É–µ–º –≥—Ä–∞—Ñ–∏–∫–∏ –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è
                train_dir = best_model_path.parent.parent
                for artifact_file in [
                    "results.png",
                    "confusion_matrix.png",
                    "F1_curve.png",
                    "PR_curve.png",
                    "results.csv",
                ]:
                    artifact_path = train_dir / artifact_file
                    if artifact_path.exists():
                        mlflow.log_artifact(
                            str(artifact_path), artifact_path="training_results"
                        )
                        logger.info(f"–ê—Ä—Ç–µ—Ñ–∞–∫—Ç –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞–Ω: {artifact_file}")

                # –õ–æ–≥–∏—Ä—É–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏
                if log_images:
                    val_images_dir = train_dir / "val_batch0_pred.jpg"
                    if val_images_dir.exists():
                        mlflow.log_artifact(
                            str(val_images_dir), artifact_path="validation_images"
                        )

            # –õ–æ–≥–∏—Ä—É–µ–º data.yaml
            data_yaml_path = Path(data_yaml)
            if data_yaml_path.exists():
                mlflow.log_artifact(str(data_yaml_path), artifact_path="dataset")

            logger.info("=" * 80)
            logger.info("–û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û –£–°–ü–ï–®–ù–û")
            logger.info("=" * 80)
            logger.info(f"MLflow Run ID: {run_id}")
            logger.info(f"–î–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∑–∞–ø—É—Å—Ç–∏—Ç–µ:")
            logger.info(f"  mlflow ui --backend-store-uri {tracking_path.absolute()}")

            return {
                "success": True,
                "run_id": run_id,
                "best_model_path": str(best_model_path),
                "metrics": numeric_metrics if "numeric_metrics" in locals() else {},
                "mlflow_uri": str(tracking_path.absolute()),
            }

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏: {e}")
            mlflow.log_param("error", str(e))
            raise


def load_best_model(model_path: str) -> YOLO:
    """
    –ó–∞–≥—Ä—É–∑–∫–∞ –ª—É—á—à–µ–π –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏

    Args:
        model_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –º–æ–¥–µ–ª–∏ .pt

    Returns:
        –ó–∞–≥—Ä—É–∂–µ–Ω–Ω–∞—è YOLO –º–æ–¥–µ–ª—å
    """
    if not Path(model_path).exists():
        raise FileNotFoundError(f"–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {model_path}")

    logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏–∑ {model_path}")
    model = YOLO(model_path)
    return model
